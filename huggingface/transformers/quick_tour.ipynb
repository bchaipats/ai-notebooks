{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b000fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets\n",
      "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.5/770.5 kB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.7\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from datasets) (1.5.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=2021.11.1\n",
      "  Using cached fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from pandas->datasets) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tokenizers, xxhash, tqdm, regex, pyyaml, pyarrow, multidict, fsspec, frozenlist, filelock, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, transformers, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.3 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.7.1 dill-0.3.6 filelock-3.8.0 frozenlist-1.3.3 fsspec-2022.11.0 huggingface-hub-0.11.1 multidict-6.0.3 multiprocess-0.70.14 pyarrow-10.0.1 pyyaml-6.0 regex-2022.10.31 responses-0.18.0 tokenizers-0.13.2 tqdm-4.64.1 transformers-4.25.1 xxhash-3.1.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a830f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: typing-extensions in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.0)\n",
      "Requirement already satisfied: wheel in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7295a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████| 629/629 [00:00<00:00, 278kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:04<00:00, 66.6MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 48.0/48.0 [00:00<00:00, 19.4kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:03<00:00, 71.4kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfedf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998449087142944}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('We are very happy to show you the Transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a0307e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the 🤗 Transformers library.\", \n",
    "                      \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651fbe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████| 1.60k/1.60k [00:00<00:00, 610kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 378M/378M [00:05<00:00, 66.2MB/s]\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████| 163/163 [00:00<00:00, 66.4kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████| 291/291 [00:00<00:00, 110kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 85.0/85.0 [00:00<00:00, 33.6kB/s]\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████| 159/159 [00:00<00:00, 66.0kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "speech_recognizer = pipeline(\"automatic-speech-recognition\",\n",
    "                             model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed856ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading soundfile-0.11.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e779d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset minds14/en-US to /home/bcp/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/aa40414f15e0f919231d617440192034af844835dc1e6a697f4b552e0551fd26...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                        \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset minds14 downloaded and prepared to /home/bcp/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/aa40414f15e0f919231d617440192034af844835dc1e6a697f4b552e0551fd26. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\",\n",
    "                       name=\"en-US\",\n",
    "                       split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce24b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\n",
    "    \"audio\",\n",
    "    Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09e456fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.2.0\n",
      "  Downloading scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=0.14\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.45.1\n",
      "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from librosa) (1.23.5)\n",
      "Collecting scikit-learn>=0.19.1\n",
      "  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting llvmlite<0.40,>=0.39.0dev0\n",
      "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from numba>=0.45.1->librosa) (65.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bcp/miniconda3/envs/ai/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Building wheels for collected packages: audioread\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23703 sha256=4d670c2360147fffaafe14617cf1809c68ec426962ef20ea3d7b233fad6f1b13\n",
      "  Stored in directory: /home/bcp/.cache/pip/wheels/da/4b/39/c5f6c4ee93b43281dda4dab5ac5f2bdf9d11074d427493cd55\n",
      "Successfully built audioread\n",
      "Installing collected packages: appdirs, threadpoolctl, scipy, llvmlite, joblib, audioread, scikit-learn, pooch, numba, resampy, librosa\n",
      "Successfully installed appdirs-1.4.4 audioread-3.0.0 joblib-1.2.0 librosa-0.9.2 llvmlite-0.39.1 numba-0.56.4 pooch-1.6.0 resampy-0.4.2 scikit-learn-1.1.3 scipy-1.9.3 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39eba470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FODING HOW I'D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE AP SO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I THURN A JOIN A COUNT']\n"
     ]
    }
   ],
   "source": [
    "result = speech_recognizer(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9edb3aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT',\n",
       " 'path': ['/home/bcp/.cache/huggingface/datasets/downloads/extracted/bb24d899a96af3a5b60107651cc3e5eb9c2f02fd22a126ec0cd9ac964245deac/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bac908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13a49ef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading:   0%|                                                                                           | 0.00/872k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   1%|█▏                                                                                | 12.3k/872k [00:00<01:01, 13.9kB/s]\u001b[A\n",
      "Downloading:   5%|███▊                                                                              | 41.0k/872k [00:01<00:20, 40.7kB/s]\u001b[A\n",
      "Downloading:   7%|█████▍                                                                            | 57.3k/872k [00:01<00:18, 45.2kB/s]\u001b[A\n",
      "Downloading:   8%|██████▌                                                                           | 69.6k/872k [00:01<00:18, 44.0kB/s]\u001b[A\n",
      "Downloading:   9%|███████▎                                                                          | 77.8k/872k [00:02<00:20, 39.0kB/s]\u001b[A\n",
      "Downloading:  10%|████████                                                                          | 86.0k/872k [00:02<00:30, 25.4kB/s]\u001b[A\n",
      "Downloading:  13%|██████████▌                                                                        | 111k/872k [00:03<00:33, 22.7kB/s]\u001b[A\n",
      "Downloading:  15%|████████████                                                                       | 127k/872k [00:05<00:51, 14.4kB/s]\u001b[A\n",
      "Downloading:  16%|█████████████▋                                                                     | 143k/872k [00:09<01:24, 8.57kB/s]\u001b[A\n",
      "Downloading:  18%|███████████████▏                                                                   | 160k/872k [00:11<01:18, 9.07kB/s]\u001b[A\n",
      "Downloading:  20%|████████████████▊                                                                  | 176k/872k [00:11<01:03, 11.0kB/s]\u001b[A\n",
      "Downloading:  22%|██████████████████▎                                                                | 193k/872k [00:12<00:50, 13.4kB/s]\u001b[A\n",
      "Downloading:  24%|███████████████████▉                                                               | 209k/872k [00:12<00:39, 16.6kB/s]\u001b[A\n",
      "Downloading:  26%|█████████████████████▍                                                             | 225k/872k [00:13<00:31, 20.7kB/s]\u001b[A\n",
      "Downloading:  28%|███████████████████████                                                            | 242k/872k [00:13<00:23, 27.0kB/s]\u001b[A\n",
      "Downloading:  30%|████████████████████████▌                                                          | 258k/872k [00:13<00:17, 34.1kB/s]\u001b[A\n",
      "Downloading:  31%|██████████████████████████                                                         | 274k/872k [00:13<00:14, 42.7kB/s]\u001b[A\n",
      "Downloading:  33%|███████████████████████████▋                                                       | 291k/872k [00:13<00:11, 51.0kB/s]\u001b[A\n",
      "Downloading:  37%|██████████████████████████████▊                                                    | 324k/872k [00:14<00:07, 70.2kB/s]\u001b[A\n",
      "Downloading:  41%|█████████████████████████████████▉                                                 | 356k/872k [00:14<00:05, 91.9kB/s]\u001b[A\n",
      "Downloading:  43%|███████████████████████████████████▍                                               | 373k/872k [00:14<00:05, 98.4kB/s]\u001b[A\n",
      "Downloading:  47%|███████████████████████████████████████                                             | 406k/872k [00:14<00:03, 127kB/s]\u001b[A\n",
      "Downloading:  50%|██████████████████████████████████████████▏                                         | 438k/872k [00:14<00:02, 149kB/s]\u001b[A\n",
      "Downloading:  52%|███████████████████████████████████████████▉                                        | 457k/872k [00:14<00:02, 152kB/s]\u001b[A\n",
      "Downloading:  54%|█████████████████████████████████████████████▋                                      | 474k/872k [00:15<00:03, 100kB/s]\u001b[A\n",
      "Downloading:  60%|█████████████████████████████████████████████████▌                                 | 520k/872k [00:15<00:03, 88.6kB/s]\u001b[A\n",
      "Downloading:  65%|██████████████████████████████████████████████████████▊                             | 569k/872k [00:16<00:02, 101kB/s]\u001b[A\n",
      "Downloading:  73%|████████████████████████████████████████████████████████████▍                      | 635k/872k [00:17<00:02, 81.6kB/s]\u001b[A\n",
      "Downloading:  75%|█████████████████████████████████████████████████████████████▉                     | 651k/872k [00:17<00:02, 76.7kB/s]\u001b[A\n",
      "Downloading:  77%|███████████████████████████████████████████████████████████████▌                   | 668k/872k [00:17<00:02, 72.2kB/s]\u001b[A\n",
      "Downloading:  78%|█████████████████████████████████████████████████████████████████                  | 684k/872k [00:18<00:04, 46.6kB/s]\u001b[A\n",
      "Downloading:  80%|██████████████████████████████████████████████████████████████████▋                | 700k/872k [00:19<00:05, 34.1kB/s]\u001b[A\n",
      "Downloading:  82%|████████████████████████████████████████████████████████████████████▏              | 717k/872k [00:20<00:05, 30.8kB/s]\u001b[A\n",
      "Downloading:  84%|█████████████████████████████████████████████████████████████████████▊             | 733k/872k [00:21<00:04, 30.1kB/s]\u001b[A\n",
      "Downloading:  86%|███████████████████████████████████████████████████████████████████████▎           | 750k/872k [00:21<00:04, 29.5kB/s]\u001b[A\n",
      "Downloading:  88%|████████████████████████████████████████████████████████████████████████▉          | 766k/872k [00:22<00:03, 29.1kB/s]\u001b[A\n",
      "Downloading:  90%|██████████████████████████████████████████████████████████████████████████▍        | 782k/872k [00:22<00:02, 32.1kB/s]\u001b[A\n",
      "Downloading:  92%|████████████████████████████████████████████████████████████████████████████       | 799k/872k [00:23<00:02, 30.2kB/s]\u001b[A\n",
      "Downloading:  93%|█████████████████████████████████████████████████████████████████████████████▌     | 815k/872k [00:23<00:01, 32.1kB/s]\u001b[A\n",
      "Downloading:  95%|███████████████████████████████████████████████████████████████████████████████▏   | 831k/872k [00:24<00:01, 26.4kB/s]\u001b[A\n",
      "Downloading:  97%|████████████████████████████████████████████████████████████████████████████████▋  | 848k/872k [00:24<00:00, 31.3kB/s]\u001b[A\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 872k/872k [00:26<00:00, 32.9kB/s]\u001b[A\n",
      "\n",
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 48.4kB/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cce28d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.7272651791572571}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\",\n",
    "                      model=model,\n",
    "                      tokenizer=tokenizer)\n",
    "classifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfb9dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c23fac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d52caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c573232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "785ee873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 14])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6af0d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07f89785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.6222, -2.7745, -0.8967,  2.0137,  3.3064],\n",
       "        [ 0.0064, -0.1258, -0.0503, -0.1655,  0.1329]],\n",
       "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ec868a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8beff02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40ce8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffdab4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████| 483/483 [00:00<00:00, 150kB/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cd822ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7527f17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading:   0%|                                                                                           | 0.00/268M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   2%|█▎                                                                                | 4.14M/268M [00:00<00:06, 41.4MB/s]\u001b[A\n",
      "Downloading:   4%|███▋                                                                              | 11.9M/268M [00:00<00:04, 61.3MB/s]\u001b[A\n",
      "Downloading:   7%|██████                                                                            | 19.8M/268M [00:00<00:03, 69.2MB/s]\u001b[A\n",
      "Downloading:  11%|████████▊                                                                         | 28.9M/268M [00:00<00:03, 77.5MB/s]\u001b[A\n",
      "Downloading:  14%|███████████▏                                                                      | 36.6M/268M [00:00<00:03, 70.0MB/s]\u001b[A\n",
      "Downloading:  16%|█████████████▍                                                                    | 43.7M/268M [00:00<00:03, 69.5MB/s]\u001b[A\n",
      "Downloading:  20%|████████████████▌                                                                 | 53.9M/268M [00:00<00:02, 79.6MB/s]\u001b[A\n",
      "Downloading:  24%|███████████████████▋                                                              | 64.2M/268M [00:00<00:02, 86.6MB/s]\u001b[A\n",
      "Downloading:  28%|██████████████████████▊                                                           | 74.5M/268M [00:00<00:02, 91.6MB/s]\u001b[A\n",
      "Downloading:  31%|█████████████████████████▋                                                        | 83.7M/268M [00:01<00:02, 90.3MB/s]\u001b[A\n",
      "Downloading:  35%|████████████████████████████▍                                                     | 92.8M/268M [00:01<00:02, 81.3MB/s]\u001b[A\n",
      "Downloading:  38%|███████████████████████████████▎                                                   | 101M/268M [00:01<00:02, 58.0MB/s]\u001b[A\n",
      "Downloading:  40%|█████████████████████████████████▍                                                 | 108M/268M [00:01<00:02, 58.4MB/s]\u001b[A\n",
      "Downloading:  44%|████████████████████████████████████▌                                              | 118M/268M [00:01<00:02, 68.1MB/s]\u001b[A\n",
      "Downloading:  48%|███████████████████████████████████████▋                                           | 128M/268M [00:01<00:01, 76.8MB/s]\u001b[A\n",
      "Downloading:  51%|██████████████████████████████████████████▎                                        | 137M/268M [00:01<00:01, 78.9MB/s]\u001b[A\n",
      "Downloading:  54%|████████████████████████████████████████████▉                                      | 145M/268M [00:01<00:01, 74.6MB/s]\u001b[A\n",
      "Downloading:  57%|███████████████████████████████████████████████▍                                   | 153M/268M [00:02<00:01, 71.5MB/s]\u001b[A\n",
      "Downloading:  60%|█████████████████████████████████████████████████▋                                 | 161M/268M [00:02<00:01, 68.8MB/s]\u001b[A\n",
      "Downloading:  63%|███████████████████████████████████████████████████▉                               | 168M/268M [00:02<00:01, 68.8MB/s]\u001b[A\n",
      "Downloading:  65%|██████████████████████████████████████████████████████                             | 175M/268M [00:02<00:01, 69.2MB/s]\u001b[A\n",
      "Downloading:  68%|████████████████████████████████████████████████████████▎                          | 182M/268M [00:02<00:01, 68.1MB/s]\u001b[A\n",
      "Downloading:  70%|██████████████████████████████████████████████████████████▍                        | 189M/268M [00:02<00:01, 67.6MB/s]\u001b[A\n",
      "Downloading:  73%|████████████████████████████████████████████████████████████▌                      | 195M/268M [00:02<00:01, 54.1MB/s]\u001b[A\n",
      "Downloading:  76%|███████████████████████████████████████████████████████████████▍                   | 205M/268M [00:02<00:00, 63.8MB/s]\u001b[A\n",
      "Downloading:  79%|█████████████████████████████████████████████████████████████████▊                 | 212M/268M [00:03<00:00, 67.4MB/s]\u001b[A\n",
      "Downloading:  82%|████████████████████████████████████████████████████████████████████▎              | 220M/268M [00:03<00:00, 70.1MB/s]\u001b[A\n",
      "Downloading:  85%|██████████████████████████████████████████████████████████████████████▌            | 228M/268M [00:03<00:00, 68.9MB/s]\u001b[A\n",
      "Downloading:  88%|████████████████████████████████████████████████████████████████████████▋          | 235M/268M [00:03<00:00, 67.9MB/s]\u001b[A\n",
      "Downloading:  90%|██████████████████████████████████████████████████████████████████████████▉        | 242M/268M [00:03<00:00, 67.4MB/s]\u001b[A\n",
      "Downloading:  93%|█████████████████████████████████████████████████████████████████████████████      | 249M/268M [00:03<00:00, 66.9MB/s]\u001b[A\n",
      "Downloading:  95%|███████████████████████████████████████████████████████████████████████████████    | 255M/268M [00:03<00:00, 66.8MB/s]\u001b[A\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 268M/268M [00:03<00:00, 69.8MB/s]\u001b[A\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d755d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./training/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb9bef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 10.4kB/s]\u001b[A\n",
      "\n",
      "Downloading:   0%|                                                                                           | 0.00/232k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   2%|█▍                                                                                | 4.10k/232k [00:02<02:44, 1.38kB/s]\u001b[A\n",
      "Downloading:   9%|███████▎                                                                          | 20.5k/232k [00:03<00:30, 6.90kB/s]\u001b[A\n",
      "Downloading:  11%|████████▋                                                                         | 24.6k/232k [00:06<00:58, 3.53kB/s]\u001b[A\n",
      "Downloading:  16%|█████████████                                                                     | 36.9k/232k [00:09<00:50, 3.84kB/s]\u001b[A\n",
      "Downloading:  21%|█████████████████▍                                                                | 49.2k/232k [00:13<00:52, 3.47kB/s]\u001b[A\n",
      "Downloading:  28%|███████████████████████▏                                                          | 65.5k/232k [00:14<00:30, 5.44kB/s]\u001b[A\n",
      "Downloading:  35%|█████████████████████████████                                                     | 81.9k/232k [00:15<00:19, 7.54kB/s]\u001b[A\n",
      "Downloading:  42%|██████████████████████████████████▊                                               | 98.3k/232k [00:16<00:13, 10.0kB/s]\u001b[A\n",
      "Downloading:  50%|█████████████████████████████████████████                                          | 115k/232k [00:16<00:09, 12.2kB/s]\u001b[A\n",
      "Downloading:  57%|██████████████████████████████████████████████▉                                    | 131k/232k [00:17<00:06, 15.1kB/s]\u001b[A\n",
      "Downloading:  64%|████████████████████████████████████████████████████▊                              | 147k/232k [00:17<00:04, 17.8kB/s]\u001b[A\n",
      "Downloading:  71%|██████████████████████████████████████████████████████████▋                        | 164k/232k [00:18<00:03, 21.1kB/s]\u001b[A\n",
      "Downloading:  78%|████████████████████████████████████████████████████████████████▌                  | 180k/232k [00:19<00:02, 19.9kB/s]\u001b[A\n",
      "Downloading:  85%|██████████████████████████████████████████████████████████████████████▍            | 197k/232k [00:19<00:01, 24.9kB/s]\u001b[A\n",
      "Downloading:  92%|████████████████████████████████████████████████████████████████████████████▎      | 213k/232k [00:20<00:00, 20.2kB/s]\u001b[A\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:21<00:00, 10.7kB/s]\u001b[A\n",
      "\n",
      "Downloading:   0%|                                                                                           | 0.00/466k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading:   3%|██▏                                                                               | 12.3k/466k [00:00<00:21, 20.7kB/s]\u001b[A\n",
      "Downloading:   9%|███████▏                                                                          | 41.0k/466k [00:01<00:11, 36.7kB/s]\u001b[A\n",
      "Downloading:  12%|██████████                                                                        | 57.3k/466k [00:02<00:21, 19.2kB/s]\u001b[A\n",
      "Downloading:  16%|████████████▉                                                                     | 73.7k/466k [00:02<00:15, 25.0kB/s]\u001b[A\n",
      "Downloading:  19%|███████████████▊                                                                  | 90.1k/466k [00:03<00:14, 25.6kB/s]\u001b[A\n",
      "Downloading:  23%|██████████████████▉                                                                | 106k/466k [00:05<00:22, 15.7kB/s]\u001b[A\n",
      "Downloading:  26%|█████████████████████▉                                                             | 123k/466k [00:09<00:43, 7.81kB/s]\u001b[A\n",
      "Downloading:  30%|████████████████████████▊                                                          | 139k/466k [00:16<01:08, 4.79kB/s]\u001b[A\n",
      "Downloading:  33%|███████████████████████████▋                                                       | 156k/466k [00:17<00:51, 5.98kB/s]\u001b[A\n",
      "Downloading:  37%|██████████████████████████████▋                                                    | 172k/466k [00:19<00:45, 6.51kB/s]\u001b[A\n",
      "Downloading:  40%|█████████████████████████████████▌                                                 | 188k/466k [00:21<00:41, 6.67kB/s]\u001b[A\n",
      "Downloading:  44%|████████████████████████████████████▍                                              | 205k/466k [00:22<00:31, 8.25kB/s]\u001b[A\n",
      "Downloading:  47%|███████████████████████████████████████▍                                           | 221k/466k [00:23<00:24, 10.0kB/s]\u001b[A\n",
      "Downloading:  51%|██████████████████████████████████████████▎                                        | 238k/466k [00:24<00:18, 12.5kB/s]\u001b[A\n",
      "Downloading:  54%|█████████████████████████████████████████████▏                                     | 254k/466k [00:24<00:13, 15.2kB/s]\u001b[A\n",
      "Downloading:  58%|████████████████████████████████████████████████▏                                  | 270k/466k [00:25<00:10, 18.1kB/s]\u001b[A\n",
      "Downloading:  62%|███████████████████████████████████████████████████                                | 287k/466k [00:25<00:07, 22.6kB/s]\u001b[A\n",
      "Downloading:  65%|█████████████████████████████████████████████████████▉                             | 303k/466k [00:25<00:05, 27.3kB/s]\u001b[A\n",
      "Downloading:  69%|████████████████████████████████████████████████████████▉                          | 319k/466k [00:25<00:04, 31.9kB/s]\u001b[A\n",
      "Downloading:  72%|███████████████████████████████████████████████████████████▊                       | 336k/466k [00:26<00:03, 38.4kB/s]\u001b[A\n",
      "Downloading:  76%|██████████████████████████████████████████████████████████████▋                    | 352k/466k [00:26<00:02, 44.7kB/s]\u001b[A\n",
      "Downloading:  79%|█████████████████████████████████████████████████████████████████▋                 | 369k/466k [00:26<00:01, 49.1kB/s]\u001b[A\n",
      "Downloading:  86%|███████████████████████████████████████████████████████████████████████▍           | 401k/466k [00:26<00:00, 67.5kB/s]\u001b[A\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:27<00:00, 17.1kB/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42975f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset[\"train\"]\n",
    "# test_dataset = dataset[\"eval\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "286662b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef9b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset[\"train\"],\n",
    "#     eval_dataset=dataset[\"test\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "801a7d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7b406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
